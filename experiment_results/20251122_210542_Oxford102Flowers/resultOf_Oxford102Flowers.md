---
date: 2025-11-23T16:09:00  
tags:
  - python
  - deep learning
  - image classification
  - Oxford102Flowers
---



# Oxford 102 Flowers å›¾åƒåˆ†ç±»å®éªŒç»“æœ

> **ğŸ“… å®éªŒæ—¥æœŸ:** 2025-11-23 16:09
>
> **ğŸ·ï¸ ä»»åŠ¡ç±»å‹:** ç»†ç²’åº¦å›¾åƒåˆ†ç±» (Fine-Grained Image Classification)


## 1. å®éªŒç¯å¢ƒ (Experimental Environment)

| ç»„ä»¶ | è§„æ ¼/ç‰ˆæœ¬ | å¤‡æ³¨ |
| :--- | :--- | :--- |
| **OS** | Rocky Linux 9.6 | |
| **GPU** | NVIDIA RTX V100 (32GB) | CUDA 13.0 |
| **Framework** | torch  2.6.0+cu118 | |
| **Python** | 3.9.21 | |
| **ä¸»è¦åº“** | torchvision 0.14, scikit-learn, matplotlib | |

## 2. æ•°æ®é›†ä»‹ç» (Dataset Overview)

1ã€**æ•°æ®é›†åç§°:** Oxford 102 Flowers

2ã€**ç±»åˆ«æ•°é‡:** 102 ç±»ï¼Œæ€»å…±8189å¼ å›¾ç‰‡

3ã€**æ•°æ®åˆ’åˆ† (Split):**

Train set: `6149` å¼ 

Validation set: `1020` å¼ 

Test set: `1020` å¼ 

> æ•°æ®é›†åˆ’åˆ†ï¼š
>
> å°†`Train set`å’Œ`Validation set`åˆå¹¶å¾—åˆ°ä¸€ä¸ªæ–°çš„æ•°æ®é›†ï¼Œç„¶åè¿›è¡Œ5æŠ˜äº¤å‰éªŒè¯ï¼Œä¿å­˜æ¯ä¸€æŠ˜æœ€å¥½çš„ç»“æœåœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæµ‹è¯•ã€‚



4ã€**é¢„å¤„ç†ä¸å¢å¼º (Preprocessing & Augmentation):**



```python
train_validation_test_transform={
        'train_transforms': transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.RandomHorizontalFlip(p=0.5),
            # å¼•å…¥RandAugment
            transforms.RandAugment(num_ops=2, magnitude=9),  # è°ƒæ•´ num_ops å’Œ magnitude ä»¥æ§åˆ¶å¼ºåº¦
            transforms.ToTensor(),
            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
            # å¼•å…¥RandomErasing
            transforms.RandomErasing(p=0.25, scale=(0.02, 0.33), ratio=(0.3, 3.3), value='random')  # value='random' ä½¿ç”¨éšæœºåƒç´ å€¼å¡«å……
        ]),
        'validation_transforms': transforms.Compose([
            transforms.Resize((256)),
            transforms.CenterCrop((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
        ]),
        'test_transforms': transforms.Compose([
            transforms.Resize((256)),
            transforms.CenterCrop((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
        ])
    }
```



## 3. æ¨¡å‹æ¶æ„ (Model Architecture)

**Backbone:**  Resnet34

**Pretrained Weights:**   æ— 

**åˆ†ç±»å¤´ (Head):** `Linear(in_features=2048, out_features=102)`

**å‚æ•°é‡ (Params) å’Œ è®¡ç®—é‡ (FLOPs)** 

```
Resnet34 on Oxford Flowers102
Command:
Params (raw): 21336998.0
Params (str): 21.34 M
MACs (raw): 3679558758.0
MACs (str): 3.68 GMac
Estimated FLOPs (2*MACs): 7359117516.0
```

**ä¸»è¦æ”¹è¿›ç‚¹:**

*åœ¨æ­¤æè¿°ä½ å¯¹æ¨¡å‹åšçš„ç‰¹æ®Šä¿®æ”¹ï¼Œä¾‹å¦‚æ·»åŠ äº† Attention æ¨¡å—ï¼Œä¿®æ”¹äº† Dropout ç‡ç­‰ã€‚*

## 4. è®­ç»ƒç»†èŠ‚ã€è¶…å‚æ•°

 (Training Details and Hyperparameter)



**Epoch:**  2000ï¼Œ **Batch Size:**  64ï¼Œ **Learning Rate:** 0.0001ï¼Œ **Weight Decay:**  0.002



**Optimizer:**

```python
AdamW(model.parameters(),lr=args.lr,weight_decay=args.weight_decay)
```

**LR Scheduler:**

```python
scheduler = lr_scheduler.OneCycleLR(
            optimizer,
            max_lr=opt.lr * 5,  # å³°å€¼å­¦ä¹ ç‡ï¼ˆé€šå¸¸ä¸ºåˆå§‹lrçš„3~10å€ï¼‰
            steps_per_epoch=len(train_loader),
            epochs=opt.epochs,
            anneal_strategy='cos',  # ä½™å¼¦é€€ç«
            pct_start=0.1,          # 10% çš„æ—¶é—´ç”¨äº warm-up
            # div_factor=25.0,        # åˆå§‹å­¦ä¹ ç‡ = max_lr / div_factor
            # final_div_factor=1e4,   # æœ€ä½å­¦ä¹ ç‡ = max_lr / final_div_factor
            # three_phase=False       # å¯é€‰ï¼šæ˜¯å¦ä¸‰é˜¶æ®µç­–ç•¥
        )
```

> ğŸ“Œ OneCycleLR å¯æœ‰æ•ˆæ›¿ä»£ä¼ ç»Ÿå­¦ä¹ ç‡è¡°å‡ç­–ç•¥ï¼Œå…¼é¡¾å¿«é€Ÿæ”¶æ•›ä¸ç¨³å®šè®­ç»ƒã€‚



**Loss Functionï¼š**

```python
criterion = nn.CrossEntropyLoss(label_smoothing=0.1).to(device)
```

> ä½¿ç”¨ **å¸¦ Label Smoothing çš„äº¤å‰ç†µæŸå¤±ï¼ˆCrossEntropyLossï¼‰**ï¼Œèƒ½å¤Ÿç¼“è§£æ¨¡å‹è¿‡è‡ªä¿¡ã€æå‡æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶åœ¨æ•°æ®å™ªå£°è¾ƒå¤šæˆ–ç±»åˆ«ä¸å‡è¡¡æ—¶æ•ˆæœæ˜¾è‘—ã€‚



**å…¶ä»–ç­–ç•¥ï¼š**  



| ç­–ç•¥                  | è¯´æ˜                                                         |
| :-------------------- | :----------------------------------------------------------- |
| **Early Stopping**    | (patience = 200), ç›‘æ§éªŒè¯æŒ‡æ ‡ï¼Œè‹¥è¿ç»­ **200 ä¸ª Epoch** æ— æå‡åˆ™æå‰åœæ­¢è®­ç»ƒï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ |
| **Gradient Clipping** | å¯¹æ¢¯åº¦è¿›è¡Œè£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§                 |
| **æ•°æ®åŠ è½½å¹¶è¡Œ**      | (num_workers = 4), ä½¿ç”¨ **4 ä¸ª DataLoader Worker** åŠ é€Ÿæ•°æ®è¯»å–ä¸å¢å¼º |



> **æ€»è®­ç»ƒæ—¶é•¿ï¼š16 h 44 min 30 s**

## 5. è¯„ä¼°ç»“æœ (Evaluation Results)

### 5.1 5æŠ˜äº¤å‰éªŒè¯ç»“æœ

| Fold     | Best Epoch | Accuracy    | Precision (micro) | Recall (micro) | Specificity | F1-score (micro) | Cohen's Kappa | Balanced Acc | AUROC      |
| -------- | ---------- | ----------- | ----------------- | -------------- | ----------- | ---------------- | ------------- | ------------ | ---------- |
| 1        | 429        | 0.9059      | 0.908             | 0.8953         | 0.9991      | 0.8936           | 0.9045        | 0.9472       | 0.9967     |
| 2        | 504        | 0.9073      | 0.9099            | 0.9036         | 0.9991      | 0.8988           | 0.9059        | 0.9513       | 0.9959     |
| 3        | 1311       | 0.9142      | 0.9176            | 0.9016         | 0.9991      | 0.9003           | 0.913         | 0.9504       | 0.9952     |
| 4        | 700        | 0.9142      | 0.918             | 0.9104         | 0.9991      | 0.9078           | 0.913         | 0.9548       | 0.9965     |
| 5        | 828        | 0.9114      | 0.8992            | 0.8988         | 0.9991      | 0.8868           | 0.9101        | 0.9489       | 0.994      |
| **Mean** | -          | 0.9106      | 0.91054           | 0.90194        | 0.9991      | 0.89746          | 0.9093        | 0.95052      | 0.99566    |
| **Std**  | -          | 0.003450797 | 0.006941931       | 0.005067386    | 0           | 0.007004456      | 0.003538926   | 0.002552959  | 0.00098102 |



æ ¸å¿ƒæŒ‡æ ‡åˆ†æï¼š



| Metric           | Mean Score | Analysis                                       |
| ---------------- | ---------- | ---------------------------------------------- |
| **Accuracy**     | **91.06%** | æ€»ä½“å‡†ç¡®ç‡è¾ƒé«˜ï¼Œæ¨¡å‹è¡¨ç°ç¨³å®šã€‚                 |
| **Precision**    | **91.05%** | æŸ¥å‡†ç‡ã€‚                                       |
| **Recall**       | **90.19%** | æŸ¥å…¨ç‡ã€‚                                       |
| **F1 Score**     | **89.75%** | ç²¾ç¡®ç‡ä¸å¬å›ç‡çš„è°ƒå’Œå¹³å‡æ•°ã€‚                   |
| **Specificity**  | **99.91%** | ç‰¹å¼‚æ€§æé«˜ï¼Œè¯¯æŠ¥ç‡ï¼ˆFalse Positiveï¼‰æä½ã€‚     |
| **Balanced Acc** | **95.05%** | å¹³è¡¡å‡†ç¡®ç‡é«˜ï¼Œè¯´æ˜æ¨¡å‹å¯¹å„ç±»åˆ«çš„é¢„æµ‹è¾ƒä¸ºå‡è¡¡ã€‚ |
| **AuRoc**        | **99.57%** | AUC æ¥è¿‘ 1.0ï¼Œæ¨¡å‹åŒºåˆ†èƒ½åŠ›æå¼ºã€‚               |
| **Cohen Kappa**  | **0.9093** | ä¸€è‡´æ€§æå¥½ (Excellent Agreement)ã€‚             |





### 5.2 æµ‹è¯•é›†è¯„ä¼°

ä¿å­˜æ¯ä¸€æŠ˜çš„æœ€å¥½ç»“æœçš„æ¨¡å‹ï¼Œä½¿ç”¨æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæµ‹è¯•ï¼š



| Fold     | Accuracy    | Precision (micro) | Recall (micro) | Specificity | F1-score (micro) | Cohen's Kappa | Balanced Acc | AUROC       |
| -------- | ----------- | ----------------- | -------------- | ----------- | ---------------- | ------------- | ------------ | ----------- |
| 1        | 0.8716      | 0.8943            | 0.8716         | 0.9987      | 0.8714           | 0.8703        | 0.9351       | 0.9949      |
| 2        | 0.8765      | 0.9012            | 0.8765         | 0.9988      | 0.8751           | 0.8752        | 0.9376       | 0.9959      |
| 3        | 0.9039      | 0.9185            | 0.9039         | 0.999       | 0.9026           | 0.903         | 0.9515       | 0.9945      |
| 4        | 0.8902      | 0.904             | 0.8902         | 0.9989      | 0.8883           | 0.8891        | 0.9446       | 0.9952      |
| 5        | 0.8882      | 0.9012            | 0.8882         | 0.9989      | 0.8857           | 0.8871        | 0.9436       | 0.9941      |
| **Mean** | 0.88608     | 0.90384           | 0.88608        | 0.99886     | 0.88462          | 0.88494       | 0.94248      | 0.99492     |
| **Std**  | 0.011317844 | 0.00799865        | 0.011317844    | 0.00010198  | 0.010985336      | 0.01146588    | 0.005751313  | 0.000614492 |



> **ğŸ’¡ ç»¼åˆè¯„ä»·:**
>
> æµ‹è¯•é›†å¹³å‡å‡†ç¡®ç‡ä¸º **88.61%**ï¼Œç•¥ä½äºäº¤å‰éªŒè¯çš„ 91.06%ã€‚è€ƒè™‘åˆ°è¿™æ˜¯ä»å¤´è®­ç»ƒçš„æ¨¡å‹ä¸”æµ‹è¯•é›†å®Œå…¨ç‹¬ç«‹ï¼Œè¯¥æ³›åŒ–æ€§èƒ½å¤„äºä¼˜ç§€æ°´å¹³ã€‚å…¶ä¸­ Fold 3 çš„æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¡¨ç°æœ€ä½³ï¼Œçªç ´äº† 90% çš„å‡†ç¡®ç‡ã€‚



## 6. å¯è§†åŒ–åˆ†æ (Visualization Analysis)

### 6.1 æ··æ·†çŸ©é˜µ (Confusion Matrix)

5æŠ˜äº¤å‰éªŒè¯æ··æ·†çŸ©é˜µï¼š



Fold 1ï¼š



![baseline_confusion_fold1](assets/baseline_confusion_fold1.png)





Fold 2ï¼š



![baseline_confusion_fold2](assets/baseline_confusion_fold2.png)





Fold 3ï¼š



![baseline_confusion_fold3](assets/baseline_confusion_fold3.png)





Fold 4ï¼š



![baseline_confusion_fold4](assets/baseline_confusion_fold4.png)





Fold 5ï¼š



![baseline_confusion_fold5](assets/baseline_confusion_fold5.png)





